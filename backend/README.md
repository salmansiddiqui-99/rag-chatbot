---
title: Physical AI RAG Chatbot
emoji: ðŸ¤–
colorFrom: blue
colorTo: cyan
sdk: docker
pinned: false
license: mit
---

# Physical AI RAG Chatbot Backend

**Purpose**: Backend API for the Physical AI & Humanoid Robotics Book RAG chatbot

## Overview

FastAPI backend service providing:
- Document ingestion from MDX book chapters (22 files, 50 chunks indexed)
- Vector search via Qdrant Cloud
- AI-generated responses via Cohere (Command model)
- Embeddings via Cohere (embed-english-v3.0, 1024-dim vectors)
- Dual-mode queries: full-book RAG + selected-text context

## Architecture

```
MDX Files â†’ Ingestion Script â†’ Qdrant (vectors) + Neon (metadata)
                                         â†“
User Query â†’ /chat endpoint â†’ Vector Search â†’ AI Generation â†’ Response
```

## Tech Stack

- **Python**: 3.11+
- **Framework**: FastAPI 0.115+, Uvicorn
- **Vector DB**: Qdrant Cloud (free tier)
- **Embeddings**: Cohere embed-english-v3.0 (1024-dim vectors)
- **AI Generation**: Cohere Command (LLM)
- **Database**: Neon Serverless Postgres

## Setup

See `../specs/001-rag-chatbot/quickstart.md` for complete setup instructions.

Quick start:
```bash
# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Initialize database
python scripts/setup_db.py

# Run server
uvicorn src.main:app --reload --port 8000
```

## API Endpoints

- `GET /` - Root health check
- `GET /api/health` - Detailed health check
- `POST /api/chatbot/query` - Submit chatbot query (RAG mode)
- `GET /api/rag/stats` - RAG statistics (indexed chunks, etc.)
- `GET /docs` - Interactive API documentation (Swagger UI)

**Example Usage**:
```bash
curl -X POST https://YOUR-USERNAME-rag-chatbot.hf.space/api/chatbot/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is ROS 2?"}'
```

## Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py            # Environment variable config
â”‚   â”œâ”€â”€ models/              # Data models (SQLAlchemy, Pydantic)
â”‚   â”œâ”€â”€ services/            # Business logic (embeddings, vector, generation, db)
â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â””â”€â”€ utils/               # Utilities (chunking, MDX parsing, prompts)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_db.py          # Database initialization
â”‚   â””â”€â”€ ingest.py            # Content ingestion script
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                # Unit tests
â”‚   â””â”€â”€ integration/         # Integration tests
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ Dockerfile               # Docker configuration for HF Spaces
â””â”€â”€ README.md                # This file
```

## Development

Run tests:
```bash
pytest tests/ --cov=src
```

Run with Docker:
```bash
docker build -t rag-chatbot .
docker run -p 8000:8000 --env-file .env rag-chatbot
```

## Deployment

Backend deployed to Hugging Face Spaces. See deployment tasks T080-T086 in `specs/001-rag-chatbot/tasks.md`.
