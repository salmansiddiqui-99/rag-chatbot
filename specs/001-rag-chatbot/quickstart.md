# Quickstart Guide: RAG Chatbot Local Development

**Feature**: Integrated RAG Chatbot for Physical AI Book
**Date**: 2025-12-22
**Purpose**: Step-by-step guide for setting up and running the RAG chatbot locally

---

## Prerequisites

- **Python**: 3.11 or higher
- **Node.js**: 18.x or higher (with npm)
- **Git**: For cloning the repository
- **Docker** (optional): For containerized development

**External Services** (free tier accounts required):
- [Cohere](https://cohere.com/) - Embeddings API (free trial)
- [Qdrant Cloud](https://qdrant.tech/cloud/) - Vector database (1GB free tier)
- [OpenRouter](https://openrouter.ai/) - AI generation API (free tier for Devstral model)
- [Neon](https://neon.tech/) - Serverless Postgres (512MB free tier)

---

## Part 1: Backend Setup

### Step 1: Clone and Checkout Branch

```bash
# Clone the repository
git clone https://github.com/your-username/physical-ai-book-rag-backend.git
cd physical-ai-book-rag-backend

# Checkout the feature branch
git checkout 001-rag-chatbot
```

### Step 2: Create Python Virtual Environment

```bash
# Using venv (built-in)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip
```

### Step 3: Install Dependencies

**Option A: Using Poetry** (recommended)
```bash
# Install Poetry if not already installed
pip install poetry

# Install dependencies from pyproject.toml
poetry install

# Activate Poetry shell
poetry shell
```

**Option B: Using pip**
```bash
# Install dependencies from requirements.txt
pip install -r requirements.txt
```

**Core Dependencies**:
- `fastapi==0.104.1` - Web framework
- `uvicorn==0.24.0` - ASGI server
- `qdrant-client==1.7.0` - Vector database client
- `cohere==4.37` - Embeddings API
- `openai==1.6.1` - AI generation (configured for OpenRouter)
- `python-dotenv==1.0.0` - Environment variable management
- `sqlalchemy==2.0.23` - ORM for Neon Postgres
- `psycopg2-binary==2.9.9` - Postgres driver
- `tiktoken==0.5.2` - Token counting
- `pytest==7.4.3` - Testing framework

### Step 4: Configure Environment Variables

1. **Copy the example environment file**:
   ```bash
   cp .env.example .env
   ```

2. **Edit `.env` file** with your API keys:

   ```env
   # OpenRouter API (for AI generation)
   OPENROUTER_API_KEY=your_openrouter_api_key_here

   # Cohere API (for embeddings)
   COHERE_API_KEY=your_cohere_trial_api_key_here

   # Qdrant Cloud (vector database)
   QDRANT_URL=https://your-cluster-id.qdrant.io:6333
   QDRANT_API_KEY=your_qdrant_api_key_here

   # Neon Serverless Postgres (metadata storage)
   NEON_DB_URL=postgresql://user:password@ep-your-project.neon.tech/dbname?sslmode=require

   # CORS Configuration (allow Docusaurus frontend)
   CORS_ORIGINS=http://localhost:3000,https://your-username.github.io

   # Optional: Logging level
   LOG_LEVEL=INFO
   ```

3. **Get API Keys**:

   - **OpenRouter**: Sign up at [openrouter.ai](https://openrouter.ai/), go to Settings → API Keys
   - **Cohere**: Sign up at [cohere.com](https://cohere.com/), navigate to Dashboard → API Keys
   - **Qdrant**: Create free cluster at [qdrant.tech/cloud](https://qdrant.tech/cloud/), copy URL and API key from cluster settings
   - **Neon**: Create project at [neon.tech](https://neon.tech/), copy connection string from Dashboard

### Step 5: Initialize Database

```bash
# Run database setup script to create tables
python scripts/setup_db.py

# Expected output:
# ✓ Connected to Neon Postgres
# ✓ Created table: document_metadata
# ✓ Database initialized successfully
```

**What this does**:
- Creates `document_metadata` table in Neon Postgres
- Sets up indexes for efficient querying
- Verifies database connectivity

### Step 6: Start Backend Server

```bash
# Start FastAPI server with auto-reload (for development)
uvicorn src.main:app --reload --port 8000

# Expected output:
# INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
# INFO:     Started reloader process [xxxxx]
# INFO:     Started server process [xxxxx]
# INFO:     Waiting for application startup.
# INFO:     Application startup complete.
```

**Verify backend is running**:
- Open browser to [http://localhost:8000/health](http://localhost:8000/health)
- Should see: `{"status": "healthy", "version": "1.0.0", "services": {...}}`

**Interactive API documentation** (auto-generated by FastAPI):
- Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
- ReDoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Step 7: Ingest Book Content

```bash
# In a new terminal (keep server running), activate virtualenv, then:

# Ingest sample chapters (assuming they exist in ../docusaurus-book/chapters)
python scripts/ingest.py --content-dir ../docusaurus-book/chapters

# Expected output:
# Parsing MDX files...
# ✓ Parsed 12 chapters
# Chunking content...
# ✓ Created 487 chunks
# Generating embeddings...
# [████████████████████████████████] 487/487 chunks embedded
# Storing in Qdrant...
# ✓ Indexed 487 chunks to Qdrant
# Updating metadata in Neon...
# ✓ Stored metadata for 12 documents
#
# Ingestion complete: 12 files, 487 chunks, 143.5 seconds
```

**Alternative: Use /ingest endpoint**:
```bash
curl -X POST http://localhost:8000/ingest \
  -H "Content-Type: application/json" \
  -d '{"content_dir": "../docusaurus-book/chapters"}'
```

**Verify indexing**:
- Check Qdrant dashboard (your cluster URL) to see `physical_ai_book` collection with ~487 points
- Query database: `SELECT * FROM document_metadata;` should show 12 rows

---

## Part 2: Frontend Setup

### Step 1: Navigate to Docusaurus Book Directory

```bash
# Assuming your Docusaurus book is in a separate directory
cd ../docusaurus-book

# Or if it's in the same repo:
cd frontend
```

### Step 2: Install Frontend Dependencies

```bash
# Install packages
npm install

# This installs:
# - @docusaurus/core
# - @docusaurus/preset-classic
# - React 18+
# - axios (for API calls)
```

**If axios is not in package.json, add it**:
```bash
npm install axios
```

### Step 3: Configure Backend API URL

Edit `docusaurus.config.js` to add backend API URL:

```javascript
// docusaurus.config.js
module.exports = {
  // ... existing config
  customFields: {
    backendApiUrl: process.env.NODE_ENV === 'development'
      ? 'http://localhost:8000'  // Local backend
      : 'https://your-username-physical-ai-book-rag.hf.space',  // Production
  },
};
```

### Step 4: Start Docusaurus Development Server

```bash
# Start dev server
npm start

# Expected output:
# [INFO] Starting the development server...
# [SUCCESS] Docusaurus website is running at http://localhost:3000/
```

**Verify chatbot widget**:
- Open [http://localhost:3000](http://localhost:3000)
- Look for chatbot widget (floating button bottom-right)
- Click to expand chat panel

---

## Part 3: Testing the Chatbot

### Test 1: Health Check

```bash
curl http://localhost:8000/health
```

**Expected response**:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "services": {
    "qdrant": "connected",
    "neon": "connected",
    "cohere": "available",
    "openrouter": "available"
  }
}
```

### Test 2: RAG Mode Query

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the main types of actuators used in humanoid robots?"
  }'
```

**Expected response**:
```json
{
  "response": "Humanoid robots use three main types of actuators: ...",
  "source_chunks": [
    {
      "chapter": "Chapter 3: Actuators",
      "section": "Electric Motors",
      "snippet": "Electric motors excel in precision positioning..."
    }
  ],
  "mode": "rag",
  "timestamp": "2025-12-22T10:45:23.123Z"
}
```

### Test 3: Selected-Text Mode Query

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain this in simpler terms",
    "selected_text": "Hydraulic actuators use pressurized fluid to generate mechanical force."
  }'
```

**Expected response**:
```json
{
  "response": "This means hydraulic actuators work by using pressurized liquid (like oil) to create strong pushing or pulling force...",
  "source_chunks": [],
  "mode": "selected_text",
  "timestamp": "2025-12-22T10:46:15.456Z"
}
```

### Test 4: Frontend Widget Interaction

1. Open [http://localhost:3000](http://localhost:3000) in browser
2. Click chatbot button (bottom-right floating button)
3. Type: "What is ROS 2?"
4. Press Enter or click Send
5. Observe loading indicator
6. Verify response appears with citations

**Test Text Selection Mode**:
1. On any book page, select a paragraph of text
2. Click "Ask about this selection" button (appears near selection)
3. Chat panel opens with selected text pre-filled
4. Ask a question like "Summarize this"
5. Verify response is based only on selected text

---

## Part 4: Running Tests

### Backend Unit Tests

```bash
# From backend directory, with virtualenv activated

# Run all tests
pytest

# Run specific test file
pytest tests/unit/test_chunking.py

# Run with verbose output
pytest -v

# Run with coverage report
pytest --cov=src --cov-report=html

# Expected output:
# ============================= test session starts ==============================
# collected 24 items
#
# tests/unit/test_chunking.py .....                                       [ 20%]
# tests/unit/test_embedding_service.py ....                               [ 37%]
# tests/unit/test_mdx_parser.py ......                                    [ 62%]
# tests/integration/test_rag_pipeline.py .....                            [ 83%]
# tests/integration/test_api_endpoints.py ....                            [100%]
#
# ============================== 24 passed in 12.34s ==============================
```

### Backend Integration Tests

```bash
# Integration tests require running services (Qdrant, Neon, Cohere, OpenRouter)
# Ensure .env is configured correctly

pytest tests/integration/ -v
```

### Frontend Component Tests

```bash
# From frontend directory

# Run Jest tests
npm test

# Run with coverage
npm test -- --coverage

# Expected output:
# PASS  src/components/ChatbotWidget/ChatbotWidget.test.tsx
#   ✓ renders chatbot button (45ms)
#   ✓ opens chat panel on button click (23ms)
#   ✓ sends query and displays response (156ms)
#   ✓ displays loading indicator while fetching (98ms)
#   ✓ shows error message on API failure (67ms)
#
# Test Suites: 1 passed, 1 total
# Tests:       5 passed, 5 total
# Snapshots:   0 total
# Time:        3.456s
```

### Manual End-to-End Testing

Follow acceptance scenarios from [spec.md](./spec.md):

**User Story 1: Ask General Questions**
1. Open chatbot widget
2. Ask: "What are the main types of actuators used in humanoid robots?"
3. Verify response synthesizes info from multiple chapters with citations

**User Story 2: Ask Questions About Selected Text**
1. Select a paragraph on any book page
2. Click "Ask about this selection"
3. Ask: "Explain this in simpler terms"
4. Verify response is based only on selected text (no additional retrieval)

**User Story 3: View Conversation History**
1. Ask 3-5 questions in sequence
2. Scroll up in chat panel
3. Verify all previous exchanges are visible
4. Close and reopen widget
5. Verify history persists within session

---

## Common Issues & Troubleshooting

### Issue 1: CORS Errors in Browser Console

**Symptom**: `Access to fetch at 'http://localhost:8000/chat' from origin 'http://localhost:3000' has been blocked by CORS policy`

**Solution**:
- Verify `CORS_ORIGINS` in `.env` includes `http://localhost:3000`
- Restart backend server after changing `.env`
- Check FastAPI CORS middleware in `src/main.py`

### Issue 2: Qdrant Connection Timeout

**Symptom**: `TimeoutError: Unable to connect to Qdrant at https://...`

**Solution**:
- Verify `QDRANT_URL` and `QDRANT_API_KEY` in `.env`
- Check Qdrant cluster status in dashboard (might be sleeping on free tier)
- Test connection manually: `curl -H "api-key: YOUR_KEY" https://YOUR_URL/collections`

### Issue 3: Empty Chatbot Responses

**Symptom**: Chat widget shows "No response" or empty message

**Solution**:
- Check if content is indexed: `curl http://localhost:8000/health` should show `qdrant: "connected"`
- Verify Qdrant dashboard shows `physical_ai_book` collection with chunks
- Run ingestion: `python scripts/ingest.py --content-dir ../docusaurus-book/chapters`
- Check backend logs for errors: `tail -f logs/app.log` (if logging configured)

### Issue 4: OpenRouter Rate Limit Errors

**Symptom**: `429 Rate Limit Exceeded` error in chat responses

**Solution**:
- Free tier has ~10 requests/minute for Devstral model
- Wait 60 seconds before retrying
- Frontend should automatically retry with exponential backoff
- Consider queuing requests or showing rate limit message to users

### Issue 5: Token Count Exceeds 1000

**Symptom**: `400 Bad Request: Query exceeds 1000 tokens`

**Solution**:
- Shorten your query
- Backend validates token count using tiktoken library
- 1000 tokens ≈ 750 words for English text

### Issue 6: Database Migration Errors

**Symptom**: `sqlalchemy.exc.ProgrammingError: relation "document_metadata" does not exist`

**Solution**:
- Run database setup script: `python scripts/setup_db.py`
- Verify Neon DB connection: Test connection string with `psql` or pgAdmin
- Check if database name exists in Neon dashboard

### Issue 7: Frontend Widget Not Appearing

**Symptom**: Docusaurus loads but no chatbot button visible

**Solution**:
- Check browser console for JavaScript errors
- Verify `src/theme/Root.tsx` includes `<ChatbotWidget />`
- Clear browser cache and hard reload (Ctrl+Shift+R)
- Verify `npm install` completed successfully

### Issue 8: Embeddings Generation Slow

**Symptom**: Ingestion takes >10 minutes for 12 chapters

**Solution**:
- Cohere free tier has rate limits; batching is implemented but may still be slow
- Consider running ingestion overnight for large books
- Check Cohere dashboard for quota usage
- Verify network connection to Cohere API

---

## Development Workflow Tips

### Hot Reload

- **Backend**: Uvicorn auto-reloads on file changes in `src/` directory
- **Frontend**: Docusaurus auto-reloads on changes in `src/`, `docs/`, `blog/` directories

### Debugging

**Backend**:
```python
# Add breakpoints in VS Code or use pdb
import pdb; pdb.set_trace()

# Or use print statements (logs to console where uvicorn is running)
print(f"Query: {query}")
```

**Frontend**:
```typescript
// Use browser DevTools Console
console.log('Chat query:', query);

// Or React DevTools extension for component inspection
```

### Resetting Data

**Clear Qdrant collection**:
```bash
curl -X DELETE http://localhost:8000/admin/reset-vector-db
# Or manually in Qdrant dashboard
```

**Clear Neon database**:
```sql
TRUNCATE TABLE document_metadata RESTART IDENTITY;
```

**Clear frontend session storage** (chat history):
- Open browser DevTools → Application → Storage → Session Storage → Clear

### Running in Production Mode

**Backend (Docker)**:
```bash
# Build Docker image
docker build -t rag-chatbot-backend .

# Run container
docker run -p 8000:8000 --env-file .env rag-chatbot-backend
```

**Frontend (Static Build)**:
```bash
# Build static site
npm run build

# Serve locally to test
npm run serve

# Deploy to GitHub Pages
npm run deploy
```

---

## Next Steps

1. **Add More Content**: Place MDX files in `chapters/` directory and re-run ingestion
2. **Customize Prompts**: Edit `src/utils/prompts.py` to adjust chatbot personality or grounding instructions
3. **Deploy to Production**: Follow [Hugging Face Spaces deployment guide](https://huggingface.co/docs/hub/spaces) for backend and [GitHub Pages docs](https://docs.github.com/en/pages) for frontend
4. **Monitor Usage**: Set up Sentry or similar for error tracking in production
5. **Optimize Performance**: Profile slow queries, add caching, implement response streaming

---

## Additional Resources

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **Docusaurus Documentation**: https://docusaurus.io/docs
- **Qdrant Documentation**: https://qdrant.tech/documentation/
- **Cohere Embeddings Guide**: https://docs.cohere.com/docs/embeddings
- **OpenRouter API Docs**: https://openrouter.ai/docs
- **Neon Postgres Guide**: https://neon.tech/docs/introduction

---

## Support & Contributions

- **Issues**: Report bugs or request features on [GitHub Issues](https://github.com/your-username/physical-ai-book/issues)
- **Contributions**: See [CONTRIBUTING.md](../CONTRIBUTING.md) for guidelines
- **Discussions**: Join our [Discord/Forum](https://example.com) for community support

---

**Last Updated**: 2025-12-22
**Version**: 1.0.0
